{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reddit Stress Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBoCFTQuokXTzjc3mlFROZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CagataySencan/StressAnalysis/blob/main/Reddit_Stress_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppor Vector Machine\n"
      ],
      "metadata": {
        "id": "tmir7qcNsOOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ep_V0GQog5rb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import  GaussianNB\n",
        "from sklearn.metrics import  confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "E0TEfZEPh1fi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "qfKK59yQh3Ul"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "-la-iWRXh5aT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "qF3IyGhNh6wA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download ruchi798/stress-analysis-in-social-media"
      ],
      "metadata": {
        "id": "PWxScyObh9e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip stress-analysis-in-social-media.zip"
      ],
      "metadata": {
        "id": "OqZTGkZOiGnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = pd.read_csv(\"dreaddit-train.csv\")\n",
        "testData = pd.read_csv((\"dreaddit-test.csv\"))"
      ],
      "metadata": {
        "id": "KiWwj6-YiTh_"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eksik veri kontrolü\n",
        "print(\"-Eğitim verisi-\\n\",trainData.isnull().sum(),\"\\n-------------\\n\",\"-Test Verisi-\\n\",testData.isnull().sum())"
      ],
      "metadata": {
        "id": "CL-RbA5Hie_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ve test datalarımızı birleştirdik\n",
        "X_Train = trainData['text']\n",
        "X_Test = testData['text']\n",
        "X = pd.concat((X_Train, X_Test), sort=False).reset_index(drop=True)\n",
        "\n",
        "Y_Train = trainData['subreddit']\n",
        "Y_Test = testData['subreddit']\n",
        "Y =  pd.concat((Y_Train, Y_Test), sort=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QoFsejv2kgfT"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Önişleme\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "id": "S6RtCh2Fr_TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Küçük harfe çevirme, stopwordslerden ve noktalama işaretlerinden temizleme\n",
        "for i in range(X.count()) : \n",
        "   \n",
        "   text = re.sub(\"[^a-zA-Z]\",' ',X[i])\n",
        "   text = text.lower()\n",
        "   text = remove_stopwords(text)\n",
        "   text = text.translate(str.maketrans('','', punctuation))\n",
        "   X[i] = text\n",
        "\n",
        "# Common wordlerden temizleme\n",
        "cnt = Counter()\n",
        "for text in X.values : \n",
        "  for word in text.split() :\n",
        "    cnt[word] += 1\n",
        "\n",
        "cnt.most_common(10)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-skuxgElu1uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
        "def remove_freqwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
        "\n",
        "X = X.apply(lambda text: remove_freqwords(text))\n"
      ],
      "metadata": {
        "id": "97xvo9zz_17Y"
      },
      "execution_count": 169,
      "outputs": []
    }
  ]
}